---
sidebar_position: 1
---

# D37S1. Logistic regression

## Supervised learning

Supervised learning, as the name suggests, has the presence of a supervisor, or a teacher.

Supervised learning is when we train the machine learning model using data that is labeled.

In supervised learning, data is already tagged with some correct answers. The machine is provided with a new set of training data. The supervised learning algorithm analyses the training data and predicts outcomes based on that labeled data.

So far, we have said that the two classic examples of supervised learning tasks are:

- classification
- regression

Regression determines the strength and the nature of the relationship between a continuous dependent variable and some independent variables.

Here is a confusing bit - we will be looking at Logistic(al) Regression today. Counterintuitively, logistic regression is a classification task.

## Linear Regression recap

Linear regression is one of the simplest models in machine learning. It consists of a predictor variable and a dependent variable that have a linear relationship, i.e., the line of best fit that summarises this relationship is a line.

The equation to denote the simple linear regression model is:

```text
y=a+b*x
```

where `y` is the dependent variable;

`a` is the intercept, the point where the line crosses the y-axis, the value of y when x = 0;

`b` is the coefficient or the slope;

`x` is the independent variable;

## Logistic regression intuition

We already know about linear regression. We know that there is a simple linear regression and it has a very short formula with one independent
variable.

We also have looked into the multiple linear regression, which has many independent variables. So we already know how to deal with this type of challenge.

On a scatterplot on the horizontal axis, we have the independent variable and on the vertical axis, we have the dependent variable.

We looked at salary versus experience.

<iframe title="Embedded cell output" src="https://embed.deepnote.com/3d592098-36ec-465f-939f-2c422a25e8db/199c9cbc-e714-479b-8c48-d1a79c749348/00012-3d285658-583d-41e9-8ab2-e7046f0ea648?height=484" height="484" width="500"/>

How do we create a model here? We use a simple linear regression.

It puts a line through our data and that line is modeling our observations so we forecast things and compare our actual observations to our model.

But what if your company sends out email offers to customers with a proposal to buy some products. They send out an offer in the email to a lot of customers to purchase certain products.

They have records of customer age and also there is a variable whether or not the customer used the offer.

<iframe title="Embedded cell output" src="https://embed.deepnote.com/291e2f34-4820-4156-bf66-22e9fd45eddd/ad230226-ca88-4a27-bc54-bc45b1c7dd59/42aa24c28e484be3b9a49aa02a886954?height=504" height="504" width="500"/>

Intuitively, we can see that there is some sort of correlation.

We can see that the observations on the bottom, there are a bit more to the left.

So can we somehow model this? We can model the probability of answers and the line we can use is below:

<iframe title="Embedded cell output" src="https://embed.deepnote.com/291e2f34-4820-4156-bf66-22e9fd45eddd/ad230226-ca88-4a27-bc54-bc45b1c7dd59/f18bdce6554b4ee1a907f93a539b9dc2?height=478" height="478" width="500"/>

## Feature Scaling

Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step. Just to give you an example — if you have multiple independent variables like age, salary, and height; With their range as (18–100 Years), (25,000–75,000 Euros), and (1–2 Meters) respectively, feature scaling would help them all to be in the same range, for example- centered around 0 or in the range (0,1) depending on the scaling technique.

In `sklearn` to scale features you can run:

```python
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
```

## Deepnote - logistic regression in Python

Duplicate the Deepnote below, attempt the tasks.

[<img
    src="/img/icons/deepnote-logo.svg"
    alt="Deepnote link"
/>](https://deepnote.com/project/logistic-regrssion-KR4vNEggQVa_ZiLp_UXt3Q/%2Flogistic_regression.ipynb)

[Link to Deepnote](https://deepnote.com/project/logistic-regrssion-KR4vNEggQVa_ZiLp_UXt3Q/%2Flogistic_regression.ipynb)
