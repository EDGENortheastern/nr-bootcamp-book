---
sidebar_position: 2
---

# D26S2. Data Cleaning in Pandas

To understand why we need to clean data, let us remind ourselves of the data science workflow. In a typical data science workflow, we often take the following steps:

- access raw data
- explore and process
- develop insights using visualizations or predictive models
- report these insights with dashboards or reports

Dirty data can appear due to the following reasons:

- duplicate values
- missing values
- misspellings
- data type errors
- legacy systems or pipeline porblems
- merging data sets
- etc.

Without making sure that data is properly cleansed in the exploration and processing phase, we will compromise the insights and reports subsequently generated.

## Getting rid of some columns

Before we start with the data cleaning process, we should check whether we can get rid of some attributes and some columns that we don't need. This enables us to continue with a leaner data frame.

One of the reasons to drop a column in a data set is: it contains a lot of missing values. The code below assesses the column entitled 'adult' for the number of non-missing values.

```python
df.adult.value_counts()
```

To remove an entire column the following Python code can be used:

```python
df.drop(columns = ['imdb_id'], inplace = True)
```

The `inplace = True` parameter allows to avoid making new columns.

## Cleaning numerical columns

Sometimes we get datasets and find that someone has helpfully added percentage signs or other non-numeric symbols to the data in a column that you expect to be numeric. But even if the data seems numeric it is worse to run:

```python
df.budget.dtype
```

The code above will identify the data type.

When you expect numeric data but the `.dtype` identified `object` you can try several methods of converting into numbers.

```python
df.budget.astype("float")
```

The code above will convert column badget into floats if convertable. However, it does not always work. The reasons could be:

- extra characters, e.g., `%`
- some data is in a totally wrong format
- etc.

You may try:

```python
df.budget = pd.to_numeric(df.budget, errors = "coerce")
```

The `errors = "coerce"` parameter will turn all invalid exceptions into `nan` values NaN or `nan` is the default missing value marker in Pandas. It does not mean the data is bad or wrong, it simply means there is no record for this field.

>NaN in Pandas means missing data, however, in other languages people often read NaN as not a number. Do not get those mixed up.

It is always worse it to count values on columns we want, e.g.,:

```python
df.budget.value_counts(dropna = False)
```

The code above will count all different values in a column `budget`. If the result shows that there are too many movies with the budget of 0 we might convert them to `nan`.

```python
df.budget = df.budget.replace(0, np.nan)
```

## Cleaning DateTime Columns

Date and time often appear in `.csvs` as objects (strings or text). There are many reasons for it. If we want to use the data to run date and time operations such as check if the date is later than today, we need to convert datetime columns into appropriate data type.

```python
df.release_date = pd.to_datetime(df.release_date, errors = "coerce")
```

## Cleaning Text / String Columns

A range of values can signify missing data if the data type is string. Missing values in Pandas should always be `nan`. To replace an empty string with the `nan` value you need:

```python
df.overview.replace(" ", np.nan, inplace = True)
```

## Removing Duplicates

Duplicates are most often caused by the unavoidable process of merging data sets. To identify duplicates:

```python
df[df.duplicated(keep =  False)].sort_values(by = "id")
```

To drop duplicates:

```python
df.drop_duplicates(subset = "id", inplace = True)
```

## Deepnote excercise

[<img
    src="/img/icons/deepnote-logo.svg"
    alt="Deepnote link"
/>](https://deepnote.com/project/data-cleansing-e6Z2lNZ7TJWzJ0uzvE40Wg/%2Fanswers.ipynb)

[Link to Deepnote](https://deepnote.com/project/data-cleansing-e6Z2lNZ7TJWzJ0uzvE40Wg/%2Fanswers.ipynb)
